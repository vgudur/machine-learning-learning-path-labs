{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "data-cleanup.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKxGEoPU3XvF",
        "colab_type": "text"
      },
      "source": [
        "# Dealing with unclean data\n",
        "\n",
        "We're going to look at data that may require some cleansing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay6MvVN93XvG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MslPEA5D3XvK",
        "colab_type": "text"
      },
      "source": [
        "## Read the admissions data that is not so clean"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHQujoDu3XvL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_location  = 'https://elephantscale-public.s3.amazonaws.com/data/college-admissions/admission-data-dirty.csv'\n",
        "\n",
        "admissions = pd.read_csv(data_location)\n",
        "print(\"admissions size : \", admissions.size)\n",
        "admissions"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dc5OHbfN3XvN",
        "colab_type": "text"
      },
      "source": [
        "## Get Summary\n",
        "See what we get.  It will skip null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY2gmu0_3XvO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO : use 'describe' functions \n",
        "admissions.describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2q2zHWNF3XvQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO : make describe include all columns\n",
        "admissions.describe(include = 'all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TM_aYzbv3XvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO : Describe more than one column : gre and gpa\n",
        "## Hint : add 'gpa' column\n",
        "admissions[['gre', 'gpa']].describe()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZK1ZFiLl3XvV",
        "colab_type": "text"
      },
      "source": [
        "## Drop all null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHvh-8YP3XvW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"raw data size : \", admissions.size)\n",
        "\n",
        "## TODO : use 'dropna' function\n",
        "dropped_na = admissions.dropna()\n",
        "print()\n",
        "print(\"after drop size : \", dropped_na.size)\n",
        "dropped_na\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jjp92ZOt3XvZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# only drop nulls from admit & gre column\n",
        "print(\"raw data size : \", admissions.size)\n",
        "\n",
        "print()\n",
        "\n",
        "dropped2 = admissions.dropna(subset=['admit', 'gre'])\n",
        "print(\"after drop size : \", dropped2.size)\n",
        "dropped2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x7Bqn9v3Xvd",
        "colab_type": "text"
      },
      "source": [
        "## Fill in the values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bHoVFCI3Xvd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO :  fill every thing with zero\n",
        "## Hint : use 'fillna'\n",
        "zero_fill = admissions.fillna(0)\n",
        "zero_fill"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bipet8EQ3Xvf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# or we can specify per column default value\n",
        "## TODO : specify different default values per column\n",
        "##        default value for gre = -100\n",
        "fill2 = admissions.fillna({'admit': -1, 'gre': -100, 'gpa':-1, 'rank':10})\n",
        "fill2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s1XAzWAA3Xvh",
        "colab_type": "text"
      },
      "source": [
        "## Replace values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9gti7F1q3Xvi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print (admissions)\n",
        "\n",
        "admissions2 = admissions.copy(deep=True)\n",
        "\n",
        "## TODO : use replace to change 800 to 1000\n",
        "## Hint : replace (800, 1000)\n",
        "admissions2['gre'].replace(800, 1000, inplace=True)\n",
        "\n",
        "print()\n",
        "print (admissions2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0BVdphHE3Xvk",
        "colab_type": "text"
      },
      "source": [
        "## Clean out RANK column"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wavscjUC3Xvl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TODO : filter out any thing other than 1,2,3,4  in rank column\n",
        "a = admissions[admissions['rank'].isin(['1','2','3','4'])]\n",
        "a"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9hmxVQb506o",
        "colab_type": "text"
      },
      "source": [
        "#Exercise 2  - Cleaning up House Sales Data (★★☆)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WdgJA0b5-_e",
        "colab_type": "text"
      },
      "source": [
        "##Read the house-sales-simplified.csv.\n",
        "> *See the shape , describe, info functions of dataframe*\n",
        "\n",
        "> *Find Numerical and Categorical columns in the data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gSFmcCML6GT3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_file_path  = 'https://elephantscale-public.s3.amazonaws.com/data/house-prices/house-sales-simplified.csv'\n",
        "df_house = pd.read_csv(data_file_path)\n",
        "\n",
        "#print ( \"\\nHouse DataFrame size: {0}\\n\".format(df_house.size))\n",
        "print ( \"\\nHouse DataFrame shape: {0}\\n\".format(df_house.shape))\n",
        "##print ( \"\\nHouse DataFrame info: {0}\\n\".format(df_house.info()))\n",
        "pd.set_option('display.float_format', lambda x: '%.5f' % x)\n",
        "\n",
        "numerical_Columns = df_house.select_dtypes([np.number]).columns.tolist()\n",
        "categorical_Columns = df_house.select_dtypes( exclude = [np.number] ).columns.tolist()\n",
        "\n",
        "numerical_Columns.remove('ID')\n",
        "numerical_Columns.remove('YrBuilt')\n",
        "numerical_Columns.remove('Bedrooms')\n",
        "\n",
        "categorical_Columns.insert(0,'Bedrooms')\n",
        "categorical_Columns.remove(\"Date\")\n",
        "print (\"\\nnumerical_Columns: {0} \\ncategorical_Columns: {1} \\n\".format(numerical_Columns,categorical_Columns  ) )\n",
        "df_house.describe(include='all')\n",
        "\n",
        "##print ( 'Date colum type is ' ,  df_house.Date.dtype)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGQ1E3R23Xvn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## see the frequency of all numerical columns and outliers\n",
        "\n",
        "sns.set(style='whitegrid', palette=\"deep\", font_scale=1.1, rc={\"figure.figsize\": [8, 5]})\n",
        "\n",
        "## distribution of all numerica columns\n",
        "##df_house[numerical_Columns].hist(bins=10, figsize=(10, 5), layout=(3, 3))\n",
        "print ( \"\\n Distribution of all numerical values \\n\")\n",
        "df_house[numerical_Columns].hist(bins=15, figsize=(15, 7), layout=(2, 3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VpGAx7pvw4GW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( \"\\nDistribution of categorical values \\n\")\n",
        "## distribution of categorical columns\n",
        "listsize = len( categorical_Columns)\n",
        "ncol = 3\n",
        "if (  listsize < ncol ):\n",
        "  ncol = listsize\n",
        "nrow = round(len(categorical_Columns)/ ncol )\n",
        "\n",
        "fig, axes_types = plt.subplots(nrows= nrow , ncols= ncol, sharex=False, sharey=True, squeeze=True, figsize=(8,4))\n",
        "\n",
        "'''\n",
        "for variable, subplot in zip(categorical_Columns, ax.flatten()):\n",
        "      sns.countplot(df_house[variable], ax=subplot)\n",
        "      for label in subplot.get_xticklabels():\n",
        "        label.set_rotation(45)\n",
        "'''\n",
        "\n",
        "for i, ax in enumerate(fig.axes):\n",
        "    if i <  listsize:\n",
        "        ax.set_xticklabels(ax.xaxis.get_majorticklabels(), rotation=45)\n",
        "        xlabel = categorical_Columns[i]\n",
        "        sns.countplot(x= df_house[xlabel] , alpha=0.7, data=df_house, ax=ax)\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5wNZ5kF5wx7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( \"\\nDistribution of SalePrice by categorical values \\n\")\n",
        "## distribution of categorical columns\n",
        "fig, ax = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=True, squeeze=True, figsize=(20,10))\n",
        "\n",
        "for variable, subplot in zip(categorical_Columns, ax.flatten()):\n",
        "      sns.boxplot(x=variable, y='SalePrice', data=df_house, ax=subplot)\n",
        "      for label in subplot.get_xticklabels():\n",
        "        label.set_rotation(90)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FHUsb1j8DwXl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"\\nFinding correlation between features \\n\")\n",
        "# Finding the relations between the variables.\n",
        "plt.figure(figsize=(20,10))\n",
        "corr_values= df_house.corr()\n",
        "sns.heatmap(corr_values,cmap=\"BrBG\",annot=True)\n",
        "##c"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8a06kO03v2o4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## Identify columns that need data cleanup\n",
        "## Hint : Zipcode\n",
        "plt.figure(figsize=(9, 8))\n",
        "'''\n",
        "sns.distplot(\n",
        "    df_house.ZipCode , bins= 10, color='g',norm_hist=False, kde=True, hist_kws={\"alpha\": 1}\n",
        ").set(xlabel='ZipCode', ylabel='Count')\n",
        "##plt.xlim(-10, df_house.ZipCode.max())\n",
        "'''\n",
        "\n",
        "##sns.violinplot(x=df_house['ZipCode'])\n",
        "sns.violinplot(x=\"ZipCode\", y= \"PropertyType\", data=df_house)\n",
        "df_Zips =  df_house[ (df_house[\"ZipCode\"]== df_house.ZipCode.min())] \n",
        "df_Zips.describe(include='all')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "84T49ZfcWn2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##df_count_by_ZipCode.describe(include='all')\n",
        "def Outlier_Finding_IQR(sourcedf):\n",
        "  print (\"\\n Finding Outliers using IQR scoring techinique\\n\")\n",
        "  Q1 = sourcedf.quantile(0.25)\n",
        "  Q3 = sourcedf.quantile(0.75)\n",
        "  IQR = Q3 - Q1\n",
        "  df_after_clearning_step2 = sourcedf[~((sourcedf < (Q1 - 1.5 * IQR)) |(sourcedf > (Q3 + 1.5 * IQR))).any(axis=1)]\n",
        "  print ( \"\\n Before {0} and after{1} clearning the outliers \\n\".format( sourcedf.shape, df_after_clearning_step2.shape ) )\n",
        "  print ( \"\\n Before \\n {0} \\n after \\n{1} \\n  \\n\".format( sourcedf.describe(include='all'), df_after_clearning_step2.describe(include='all') ) ) \n",
        "\n",
        "##Outlier_Finding_IQR ( df_house)\n",
        "##Outlier_Finding_IQR ( df_count_by_ZipCode)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGFAfDwdZrrI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "all_zips = df_house.ZipCode.count().astype(int)\n",
        "positive_zips = df_house.ZipCode[df_house['ZipCode'] > 0].count().astype(int)\n",
        "missing_zips = df_house.ZipCode[df_house['ZipCode'] < 1].count().astype(int)\n",
        "print(f'All Zips {all_zips}, Positive {positive_zips} , Missing {missing_zips}')\n",
        "print(f'Validity {(positive_zips * 100/all_zips):.2f}%')\n",
        "\n",
        "df = pd.DataFrame({'Zips':['All', 'Positive', 'Missing'], 'Records':[all_zips, positive_zips, missing_zips]})\n",
        "ax = df.plot.bar(x='Zips', y='Records', rot=0)\n",
        "ax.set_ylabel('Zips')\n",
        "ax.plot()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P3p-FEJEZ9ml",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "###Convert SaleDate to actual date type\n",
        "print ( \"Fist check existing type of Date filed : \", df_house.Date.dtype )\n",
        "\n",
        "# Check first if we will have wrong conversions\n",
        "print('Nulls in conversion', pd.to_datetime(df_house['Date']).isnull().sum())\n",
        "print('NaN in conversion', pd.to_datetime(df_house['Date']).isna().sum())\n",
        "\n",
        "# Convert and rename column\n",
        "if pd.to_datetime(df_house['Date']).isna().sum() == 0 and pd.to_datetime(df_house['Date']).isnull().sum() == 0:\n",
        "    df_house['SaleDate'] = pd.to_datetime(df_house['Date'])\n",
        "    print('conversion of strings to datetime was successful')\n",
        "df_house.SaleDate.describe()\n",
        "print ( \"Check New field data type : \", df_house.SaleDate.dtype )\n",
        "df_house.drop(columns=['Date'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MGHu_ulkes8w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Do a barplot of houses sold per year\n",
        "df_house['Sale_Year'] = pd.DatetimeIndex(df_house['SaleDate']).year\n",
        "df_house['Sale_Month'] = pd.DatetimeIndex(df_house['SaleDate']).month\n",
        "\n",
        "sns.countplot(x=df_house.Sale_Year)\n",
        "plt.title(\"Sales by Year\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7eBnC7LgsyO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# What percentage of data is clean?\n",
        "def calculate_missing_values_percent_by_columns(diff):\n",
        "  for col in diff.columns:\n",
        "    pct_missing = np.mean(diff[col].isnull())\n",
        "    pct_missing = round(pct_missing*100, 3)\n",
        "    pct_clean = 100 - pct_missing\n",
        "    \n",
        "    print('{0: >20} - pecent clean: {1: >7}% - percent missing: {2: >7}%'.format(col,pct_clean,  pct_missing))\n",
        "def missing_zero_values_table(df):\n",
        "        zero_val = (df == 0.00).astype(int).sum(axis=0)\n",
        "        mis_val = df.isnull().sum()\n",
        "        mis_val_percent = 100 *( df.isnull().sum() / len(df) )\n",
        "        mz_table = pd.concat([zero_val, mis_val, mis_val_percent], axis=1)\n",
        "        mz_table = mz_table.rename(\n",
        "        columns = { 0 : 'Zero Values',1 : 'Missing Values', 2 : '% of Missing Values'})\n",
        "        mz_table['Total Zero Missing Values'] = mz_table['Zero Values'] + mz_table['Missing Values']\n",
        "        mz_table['% Total Zero Missing Values'] = 100 * ( mz_table['Total Zero Missing Values'] / len(df) )\n",
        "        mz_table['Data Type'] = df.dtypes\n",
        "        mz_table['Data Length'] = len(df)\n",
        "        mz_table = mz_table[\n",
        "            mz_table.iloc[:,1] != 0].sort_values(\n",
        "        '% of Missing Values', ascending=False).round(3)\n",
        "\n",
        "        print (\"Your selected dataframe has \" + str(df.shape[1]) + \" columns and \" + str(df.shape[0]) + \" Rows.\\n\"      \n",
        "            \"There are \" + str(mz_table.shape[0]) +\n",
        "              \" columns that have missing values.\")\n",
        "#         mz_table.to_excel('D:/sampledata/missing_and_zero_values.xlsx', freeze_panes=(1,0), index = False)\n",
        "        return mz_table\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5SsJ07Ud_Saz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#What percentage of data is clen?\n",
        "print ( 'Percent of Cleanness in the data - Method1')\n",
        "missing_zero_values_table(df_house)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNQGx3_0HJJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print ( 'Percent of Cleanness in the data - Method2')\n",
        "\n",
        "calculate_missing_values_percent_by_columns(df_house )\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}

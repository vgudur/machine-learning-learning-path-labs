{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering : K-Means : Uber Pickups\n",
    "\n",
    "This is data of Uber pickups in New York City.  \n",
    "The data is from this [kaggle competition](https://www.kaggle.com/fivethirtyeight/uber-pickups-in-new-york-city).\n",
    "\n",
    "Sample data looks like this\n",
    "```\n",
    "\"Date_Time\",\"Lat\",\"Lon\",\"Base\"\n",
    "\"4/1/2014 0:11:00\",40.769,-73.9549,\"B02512\"\n",
    "\"4/1/2014 0:17:00\",40.7267,-74.0345,\"B02512\"\n",
    "\"4/1/2014 0:21:00\",40.7316,-73.9873,\"B02512\"\n",
    "\"4/1/2014 0:28:00\",40.7588,-73.9776,\"B02512\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load the Data\n",
    "We will also specify schema to reduce loading time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request\n",
    "\n",
    "## sample file with 10,000 records\n",
    "data_location=\"../data/uber-nyc/uber-sample-10k.csv\"\n",
    "data_url = 'https://elephantscale-public.s3.amazonaws.com/data/uber-nyc/uber-sample-10k.csv'\n",
    "\n",
    "## larger file with about 500k records\n",
    "# data_location = \"../data/uber-nyc/uber-raw-data-apr14.csv.gz\"\n",
    "# data_url = 'https://elephantscale-public.s3.amazonaws.com/data/uber-nyc/uber-raw-data-apr14.csv.gz'\n",
    "\n",
    "if not os.path.exists (data_location):\n",
    "    data_location = os.path.basename(data_location)\n",
    "    if not os.path.exists(data_location):\n",
    "        print(\"Downloading : \", data_url)\n",
    "        urllib.request.urlretrieve(data_url, data_location)\n",
    "print('data_location:', data_location)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = pd.read_csv(data_location)\n",
    "print (dataset.info())\n",
    "dataset.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Cleanup data\n",
    "make sure our data is clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_pickups_clean = dataset.dropna(subset=['Lat', 'Lon'])\n",
    "print ('uber_picksups_clean : ', uber_pickups_clean.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 : Create Feature Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TODO : create a feature vectors using 'Lat'  and 'Lon'  attributes\n",
    "x = uber_pickups_clean[['???', '???']]\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 : Run K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "## TODO : start with num_clusters=4\n",
    "num_clusters = ???\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "model = kmeans.fit(x)\n",
    "\n",
    "wssse = model.inertia_\n",
    "\n",
    "print (\"num_clusters = {},  WSSSE = {:,}\".format(num_clusters, wssse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Let's find the best K - Hyperparameter tuning\n",
    "\n",
    "Let's try iterating and plotting over values of k, so we can practice using the elbow method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "kvals = []\n",
    "wssses = []\n",
    "\n",
    "## TODO : loop over k values from 2 to 10\n",
    "for k in range(2, ???):\n",
    "    kmeans = KMeans(n_clusters=k)\n",
    "    t1 = time.perf_counter()\n",
    "    model = kmeans.fit(x)\n",
    "    t2 = time.perf_counter()\n",
    "    wssse = model.inertia_\n",
    "    print (\"k={},  wssse={},  time took {:,.2f} ms\".format(k,wssse, ((t2-t1)*1000)))\n",
    "    kvals.append(k)\n",
    "    wssses.append(wssse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame({'k': kvals, 'wssse':wssses})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot\n",
    "\n",
    "pyplot.plot(kvals, wssses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6 : Let's run K-Means with the best K we have choosen\n",
    "From the graph above, choose a good K value.  We wwill use that below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "\n",
    "## TODO : choose an appropriate k\n",
    "## pick from elbow region from the graph above\n",
    "num_clusters = ???\n",
    "kmeans = KMeans(n_clusters=num_clusters)\n",
    "\n",
    "model = kmeans.fit(x)\n",
    "\n",
    "wssse = model.inertia_\n",
    "\n",
    "print (\"num_clusters = {},  WSSSE = {:,}\".format(num_clusters, wssse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(x)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uber_pickups_clean['prediction'] = predictions\n",
    "uber_pickups_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Cluster Center and Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count = uber_pickups_clean.groupby(\"prediction\").size()\n",
    "cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_count.sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8 : Ploting time!\n",
    "We are going to plot the results now.  \n",
    "Since we are dealing with GEO co-ordinates, let's use Google Maps!  \n",
    "\n",
    "Go to the following URL :  \n",
    "[https://jsfiddle.net/sujee/omypetfu/](https://jsfiddle.net/sujee/omypetfu/)\n",
    "\n",
    "- Run the code cell below\n",
    "- copy paste the output into Javascript section of the JSFiddle Editor (lower left)\n",
    "- and click 'Run'  (top nav bar)\n",
    "- Click on 'tidy' (top nav bar)  to cleanup code\n",
    "\n",
    "See the following image \n",
    "\n",
    "<img src=\"../assets/images/kmeans_uber_trips_map.png\" style=\"border: 5px solid grey ; max-width:100%;\" />\n",
    "\n",
    "You will be rewarded with a beautiful map of clusters on Google Maps\n",
    "\n",
    "<img src=\"../assets/images/Kmeans_uber_trips.png\" style=\"border: 5px solid grey ; max-width:100%;\" />\n",
    "\n",
    "Optional\n",
    "- You can 'fork' the snippet and keep tweaking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### generate Javascript\n",
    "s1 = \"var clusters = {\"\n",
    "\n",
    "s2 = \"\"\n",
    "\n",
    "prediction_count = uber_pickups_clean.groupby(\"prediction\").size()\n",
    "total_count = 0\n",
    "cluster_centers = model.cluster_centers_\n",
    "for i in range(0, num_clusters):\n",
    "    count = prediction_count[i]\n",
    "    lat = cluster_centers[i][0]\n",
    "    lng = cluster_centers[i][1]\n",
    "    total_count = total_count + count\n",
    "    if (i > 0):\n",
    "        s2 = s2 + \",\"\n",
    "    s2 = s2 + \" {}: {{ center: {{ lat: {}, lng: {} }}, count: {} }}\".\\\n",
    "        format(i, lat, lng, count)\n",
    "    #s2 = s2 + \"{}: {{  center: {{ }}, }}\".format(i)\n",
    "\n",
    "s3 = s1 + s2 + \"};\"\n",
    "\n",
    "s4 = \"\"\"\n",
    "function initMap() {\n",
    "  // Create the map.\n",
    "  var map = new google.maps.Map(document.getElementById('map'), {\n",
    "    zoom: 10,\n",
    "    center: {\n",
    "      lat: 40.77274573,\n",
    "      lng: -73.94\n",
    "    },\n",
    "    mapTypeId: 'roadmap'\n",
    "  });\n",
    "\n",
    "  // Construct the circle for each value in citymap.\n",
    "  // Note: We scale the area of the circle based on the population.\n",
    "  for (var cluster in clusters) {\n",
    "    // Add the circle for this city to the map.\n",
    "    var cityCircle = new google.maps.Circle({\n",
    "      strokeColor: '#FF0000',\n",
    "      strokeOpacity: 0.8,\n",
    "      strokeWeight: 2,\n",
    "      fillColor: '#FF0000',\n",
    "      fillOpacity: 0.35,\n",
    "      map: map,\n",
    "      center: clusters[cluster].center,\n",
    "\"\"\"\n",
    "\n",
    "s5 = \"radius: clusters[cluster].count / {} * 100 * 300 }});  }}}}\".format(total_count)\n",
    "\n",
    "# final\n",
    "s = s3 + s4 + s5\n",
    "\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Let's analyze some more data\n",
    "\n",
    "- In Step-1 select the data_file to \n",
    "```\n",
    "data_file = \"../data/uber-nyc/uber-raw-data-apr14.csv.gz\"\n",
    "```\n",
    "- And select 'Cell --> Run All'  to execute all code blocks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10 : Running the script\n",
    "\n",
    "**Use the download script**\n",
    "\n",
    "```bash\n",
    "cd   ~/data/uber-nyc\n",
    "./download-data.sh\n",
    "```\n",
    "\n",
    "This will download more data.\n",
    "\n",
    "As we run on larger dataset, the execution will take longer and Jupyter notebook might time out.  So let's run this in command line / script mode\n",
    "\n",
    "```bash\n",
    "\n",
    "$    cd   ~/ml-labs-python/clustering\n",
    "\n",
    "$    time  python  kmeans-uber.py 2> logs\n",
    "\n",
    "```\n",
    "\n",
    "Watch the output\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

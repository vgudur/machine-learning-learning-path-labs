{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We are going to do recommendations on MovieLens (netflix) type data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# install surprise package\n",
    "# https://surprise.readthedocs.io/en/stable/index.html\n",
    "\n",
    "!pip install surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import KNNBaseline, SVD\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "from surprise import accuracy\n",
    "\n",
    "import io  # needed because of weird encoding of u.item file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1 - Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')\n",
    "print (\"downloaded data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2 - Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "## Train the algo\n",
    "\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
    "algo = KNNBaseline(sim_options=sim_options)\n",
    "\n",
    "\n",
    "algo.fit(trainset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3 - Calculate The RMSE \n",
    "\n",
    "We want to see how our model does.\n",
    "\n",
    "Anything less than plus or minus 0.5 star should be considered a success. That means on a scale of one to five we were less than half a star off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = trainset.build_testset()\n",
    "predictions = algo.test(testset)\n",
    "# RMSE should be low as we are biased\n",
    "accuracy.rmse(predictions, verbose=True) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4 - Parse Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_item_names():\n",
    "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
    "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
    "    \"\"\"\n",
    "\n",
    "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
    "    rid_to_name = {}\n",
    "    name_to_rid = {}\n",
    "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
    "        for line in f:\n",
    "            line = line.split('|')\n",
    "            rid_to_name[line[0]] = line[1]\n",
    "            name_to_rid[line[1]] = line[0]\n",
    "\n",
    "    return rid_to_name, name_to_rid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import get_dataset_dir\n",
    "\n",
    "# Read the mappings raw id <-> movie name\n",
    "rid_to_name, name_to_rid = read_item_names()\n",
    "\n",
    "print (\"rid_to_name:\")\n",
    "iterator = iter(rid_to_name.items())\n",
    "for i in range(10):\n",
    "    print(next(iterator))\n",
    "\n",
    "print()\n",
    "print (\"name_to_rid:\")\n",
    "iterator = iter(name_to_rid.items())\n",
    "for i in range(10):\n",
    "    print(next(iterator))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5 - Do Recommendations\n",
    "\n",
    "Find similar movies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve inner id of the movie Toy Story\n",
    "\n",
    "movie_name = 'Toy Story (1995)'\n",
    "# movie_name = 'Get Shorty (1995)'\n",
    "\n",
    "movie_raw_id = name_to_rid[movie_name]\n",
    "movie_inner_id = algo.trainset.to_inner_iid(movie_raw_id)\n",
    "\n",
    "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
    "neighbors = algo.get_neighbors(movie_inner_id, k=10)\n",
    "\n",
    "# Convert inner ids of the neighbors into names.\n",
    "neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
    "                       for inner_id in neighbors)\n",
    "neighbors = (rid_to_name[rid]\n",
    "                       for rid in neighbors)\n",
    "\n",
    "print()\n",
    "print('The 10 nearest neighbors for :  ', movie_name)\n",
    "for m in neighbors:\n",
    "    print(m)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "colab": {
      "name": "1-recs-movielens.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_x52rOzjrkj"
      },
      "source": [
        "### We are going to do recommendations on MovieLens (netflix) type data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tZshzYWjrkp",
        "outputId": "8aed5652-a07e-46b6-a437-a38db089d6ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# install surprise package\n",
        "# https://surprise.readthedocs.io/en/stable/index.html\n",
        "\n",
        "!pip install surprise"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting surprise\n",
            "  Downloading https://files.pythonhosted.org/packages/61/de/e5cba8682201fcf9c3719a6fdda95693468ed061945493dea2dd37c5618b/surprise-0.1-py2.py3-none-any.whl\n",
            "Collecting scikit-surprise\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/97/37/5d334adaf5ddd65da99fc65f6507e0e4599d092ba048f4302fe8775619e8/scikit-surprise-1.1.1.tar.gz (11.8MB)\n",
            "\u001b[K     |████████████████████████████████| 11.8MB 5.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (0.17.0)\n",
            "Requirement already satisfied: numpy>=1.11.2 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.18.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.4.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from scikit-surprise->surprise) (1.15.0)\n",
            "Building wheels for collected packages: scikit-surprise\n",
            "  Building wheel for scikit-surprise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.1-cp36-cp36m-linux_x86_64.whl size=1670924 sha256=5677c10838a4d7ccb3e9b2a1abd5641371d8eb46570dbbace3f1b20213ed77ab\n",
            "  Stored in directory: /root/.cache/pip/wheels/78/9c/3d/41b419c9d2aff5b6e2b4c0fc8d25c538202834058f9ed110d0\n",
            "Successfully built scikit-surprise\n",
            "Installing collected packages: scikit-surprise, surprise\n",
            "Successfully installed scikit-surprise-1.1.1 surprise-0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZsnyyCM3jrkq"
      },
      "source": [
        "from surprise import KNNBaseline, SVD\n",
        "from surprise import Dataset\n",
        "from surprise.model_selection import cross_validate\n",
        "from surprise import accuracy\n",
        "\n",
        "import io  # needed because of weird encoding of u.item file\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tgqYYOsjrkr"
      },
      "source": [
        "## Step 1 - Read Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsK--bshjrkr",
        "outputId": "0acdd3e6-e8d0-4c46-dcb4-dbc41a1e02b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Load the movielens-100k dataset (download it if needed).\n",
        "data = Dataset.load_builtin('ml-100k')\n",
        "print (\"downloaded data\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset ml-100k could not be found. Do you want to download it? [Y/n] y\n",
            "Trying to download dataset from http://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
            "Done! Dataset ml-100k has been saved to /root/.surprise_data/ml-100k\n",
            "downloaded data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J8ze0ZR0jrkr"
      },
      "source": [
        "## Step 2 - Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHKO3lLjjrkr",
        "outputId": "6d85aced-e3e2-41af-984b-4f6d0509ae9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "%%time\n",
        "\n",
        "## Train the algo\n",
        "\n",
        "trainset = data.build_full_trainset()\n",
        "\n",
        "sim_options = {'name': 'pearson_baseline', 'user_based': False}\n",
        "algo = KNNBaseline(sim_options=sim_options)\n",
        "\n",
        "\n",
        "algo.fit(trainset)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "CPU times: user 2.53 s, sys: 70.6 ms, total: 2.6 s\n",
            "Wall time: 2.61 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUYpjmwhjrks",
        "outputId": "8f02cb98-8052-4b69-b30e-4ab664f2faa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Run 5-fold cross-validation and print results.\n",
        "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Estimating biases using als...\n",
            "Computing the pearson_baseline similarity matrix...\n",
            "Done computing similarity matrix.\n",
            "Evaluating RMSE, MAE of algorithm KNNBaseline on 5 split(s).\n",
            "\n",
            "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
            "RMSE (testset)    0.9239  0.9191  0.9141  0.9156  0.9119  0.9169  0.0042  \n",
            "MAE (testset)     0.7249  0.7212  0.7157  0.7181  0.7158  0.7191  0.0035  \n",
            "Fit time          1.91    1.92    1.93    2.01    1.94    1.94    0.04    \n",
            "Test time         5.07    4.75    4.98    4.78    5.13    4.94    0.15    \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'fit_time': (1.9122724533081055,\n",
              "  1.9188756942749023,\n",
              "  1.9316704273223877,\n",
              "  2.0105323791503906,\n",
              "  1.9439971446990967),\n",
              " 'test_mae': array([0.72485881, 0.72122852, 0.71572297, 0.71805951, 0.71576478]),\n",
              " 'test_rmse': array([0.92393415, 0.91908774, 0.91407964, 0.91561212, 0.91189253]),\n",
              " 'test_time': (5.066446781158447,\n",
              "  4.753808259963989,\n",
              "  4.981435060501099,\n",
              "  4.781335115432739,\n",
              "  5.130431413650513)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiPtOeQ0jrks"
      },
      "source": [
        "## Step 3 - Calculate The RMSE \n",
        "\n",
        "We want to see how our model does.\n",
        "\n",
        "Anything less than plus or minus 0.5 star should be considered a success. That means on a scale of one to five we were less than half a star off."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2IrnRNYjrks",
        "outputId": "87a81592-e0cf-421b-e6aa-3ead467b4977",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "testset = trainset.build_testset()\n",
        "predictions = algo.test(testset)\n",
        "# RMSE should be low as we are biased\n",
        "accuracy.rmse(predictions, verbose=True) \n",
        "\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RMSE: 0.5584\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.558390314020892"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nYs596NKjrks"
      },
      "source": [
        "## Step 4 - Parse Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "19D_a1pbjrkt"
      },
      "source": [
        "def read_item_names():\n",
        "    \"\"\"Read the u.item file from MovieLens 100-k dataset and return two\n",
        "    mappings to convert raw ids into movie names and movie names into raw ids.\n",
        "    \"\"\"\n",
        "\n",
        "    file_name = get_dataset_dir() + '/ml-100k/ml-100k/u.item'\n",
        "    rid_to_name = {}\n",
        "    name_to_rid = {}\n",
        "    with io.open(file_name, 'r', encoding='ISO-8859-1') as f:\n",
        "        for line in f:\n",
        "            line = line.split('|')\n",
        "            rid_to_name[line[0]] = line[1]\n",
        "            name_to_rid[line[1]] = line[0]\n",
        "\n",
        "    return rid_to_name, name_to_rid"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EA8Evo3ajrkt",
        "outputId": "a71d5df5-18bc-4609-b093-29c57059532b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from surprise import get_dataset_dir\n",
        "\n",
        "# Read the mappings raw id <-> movie name\n",
        "rid_to_name, name_to_rid = read_item_names()\n",
        "\n",
        "print (\"rid_to_name:\")\n",
        "iterator = iter(rid_to_name.items())\n",
        "for i in range(10):\n",
        "    print(next(iterator))\n",
        "\n",
        "print()\n",
        "print (\"name_to_rid:\")\n",
        "iterator = iter(name_to_rid.items())\n",
        "for i in range(10):\n",
        "    print(next(iterator))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "rid_to_name:\n",
            "('1', 'Toy Story (1995)')\n",
            "('2', 'GoldenEye (1995)')\n",
            "('3', 'Four Rooms (1995)')\n",
            "('4', 'Get Shorty (1995)')\n",
            "('5', 'Copycat (1995)')\n",
            "('6', 'Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)')\n",
            "('7', 'Twelve Monkeys (1995)')\n",
            "('8', 'Babe (1995)')\n",
            "('9', 'Dead Man Walking (1995)')\n",
            "('10', 'Richard III (1995)')\n",
            "\n",
            "name_to_rid:\n",
            "('Toy Story (1995)', '1')\n",
            "('GoldenEye (1995)', '2')\n",
            "('Four Rooms (1995)', '3')\n",
            "('Get Shorty (1995)', '4')\n",
            "('Copycat (1995)', '5')\n",
            "('Shanghai Triad (Yao a yao yao dao waipo qiao) (1995)', '6')\n",
            "('Twelve Monkeys (1995)', '7')\n",
            "('Babe (1995)', '8')\n",
            "('Dead Man Walking (1995)', '9')\n",
            "('Richard III (1995)', '10')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGYR8xSyjrkt"
      },
      "source": [
        "## Step 5 - Do Recommendations\n",
        "\n",
        "Find similar movies\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9TIi4sZjrkt",
        "outputId": "8726ebb3-b3ce-4744-e101-1da5f91bd41a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Retrieve inner id of the movie Toy Story\n",
        "\n",
        "movie_name = 'Toy Story (1995)'\n",
        "# movie_name = 'Get Shorty (1995)'\n",
        "\n",
        "movie_raw_id = name_to_rid[movie_name]\n",
        "movie_inner_id = algo.trainset.to_inner_iid(movie_raw_id)\n",
        "\n",
        "# Retrieve inner ids of the nearest neighbors of Toy Story.\n",
        "neighbors = algo.get_neighbors(movie_inner_id, k=10)\n",
        "\n",
        "# Convert inner ids of the neighbors into names.\n",
        "neighbors = (algo.trainset.to_raw_iid(inner_id)\n",
        "                       for inner_id in neighbors)\n",
        "neighbors = (rid_to_name[rid]\n",
        "                       for rid in neighbors)\n",
        "\n",
        "print()\n",
        "print('The 10 nearest neighbors for :  ', movie_name)\n",
        "for m in neighbors:\n",
        "    print(m)\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "The 10 nearest neighbors for :   Toy Story (1995)\n",
            "Lion King, The (1994)\n",
            "Raiders of the Lost Ark (1981)\n",
            "Liar Liar (1997)\n",
            "Beauty and the Beast (1991)\n",
            "E.T. the Extra-Terrestrial (1982)\n",
            "Dragonheart (1996)\n",
            "Craft, The (1996)\n",
            "That Thing You Do! (1996)\n",
            "Aladdin (1992)\n",
            "Private Parts (1997)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}